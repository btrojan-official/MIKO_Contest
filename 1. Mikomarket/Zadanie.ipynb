{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<h1>Mikomarket</h1>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Wstęp</h1>\n",
    "Twój znajomy Marek Adamczyk, pasjonat polityki i amatorski inwestor, postanowił \"zainwestować\" na Mikomarket, nowo otwartym rynku prognoz, przewidując wyniki najbliższych wyborów. Zorientował się jednak, że jednym z znaczących wskaźników są tweety znanych polityków — ich treści momentalnie wpływają na kursy zakładów i giełdy opinii. Niestety, ręczne monitorowanie tych tweetów to wyścig z czasem, a jego umiejętności programistyczne ograniczyły się do stworzenia scrapera, który potrafi pobrać tylko treść tweeta, bez wskazania autora.\n",
    "\n",
    "Rynek jest bezlitosny, a poświęcenie kilku sekund, aby sprawdzić czy dany post jest autorstwa Korwina, czy Żukowskiej, może kosztować fortunę. Dlatego X przyszedł do Ciebie — swojego zaufanego znajomego-informatyka, z propozycją nie do odrzucenia. Prosi o stworzenie modelu, który w mgnieniu oka przypisze tweet do odpowiedniego polityka, a jako wynagrodzenie zaproponował część swoich zarobków. Pomożesz mu?\n",
    "\n",
    "# <h2>Dostarczone pliki</h2>\n",
    "\n",
    "- `train.csv` - Dane treningowe: zawiera treści tweetów oraz ich autorów.\n",
    "- `test.csv` - Dane testowe: analogiczne do `train.csv`, ale bez oznaczonych autorów (wykorzystasz je do predykcji).\n",
    "- `przykodp.csv` - Przykładowy plik w formacie w jakim ma być `odpowiedzi.csv`.\n",
    "- `Zadanie.ipynb` - Notebook, który pomoże Ci rozpocząć pracę nad modelem.\n",
    "\n",
    "\n",
    "# <h2>Twoje zadanie</h2>\n",
    "\n",
    "### **1. Stworzenie modelu:**\n",
    "\n",
    "- Wykorzystaj model allegro/herbert-base-cased.\n",
    "- Zaimplementuj klasyfikator oparty na HerBERT, który przypisze tweet do jednego z pięciu autorów.\n",
    "- Wybierz odpowiednie hiperparametry, takie jak learning rate, batch size i liczba epok.\n",
    "- Możesz użyć np. biblioteki `unicodedata` do dekodowania emotikonów w tweetach.\n",
    "\n",
    "### **2. Trening i ewaluacja:**\n",
    "\n",
    "- Podziel dane na zbiór treningowy i walidacyjny.\n",
    "- Wytrenuj model na zbiorze treningowym.\n",
    "- Zmierz celność na zbiorze walidacyjnym.\n",
    "\n",
    "### **3. Predykcja na zbiorze testowym:**\n",
    "\n",
    "- Wykorzystaj wytrenowany model do przypisania autorów tweetów w zbiorze testowym.\n",
    "- Wyeksportuj predykcje aby były w takim samym formacie jak jest plik test.csv\n",
    " \n",
    "\n",
    "\n",
    "# <h2>Ograniczenia</h2>\n",
    "\n",
    "- Czas działania twojego kodu(trening i ewaluacja) na T4 na Google Colab powinien wynosić maksymalnie 10 minut.\n",
    "- Do dyspozycji masz model typu BERT: allegro/herbert-base-cased oraz tokenizer allegro/herbert-base-cased. Nie wolno korzystać z innych uprzednio wytrenowanych modeli oraz ze zbiorów danych innych niż dostarczony.\n",
    "- Twój kod może trenować się tylko i wyłącznie na danych z pliku train.csv.\n",
    "- Wszystkie dopuszczalne biblioteki są dostępne w pliku requirements.txt\n",
    "\n",
    "\n",
    "<h2>Ocenianie</h2>\n",
    "\n",
    "Ocena zależy od wartości accuracy w sposób liniowy, przy czym:\n",
    "\n",
    "- Jeśli `accuracy < 0.2`, to liczba punktów wynosi 0.\n",
    "- Jeśli `accuracy >= 0.7`, to liczba punktów wynosi 1.\n",
    "- Dla wartości `accuracy` pomiędzy 0.2 a 0.7, liczba punktów rośnie liniowo.\n",
    "\n",
    "Wzór na obliczenie punktów (P):\n",
    "\n",
    "$$ P = \\frac{accuracy - 0.2}{0.5} $$\n",
    "\n",
    "Gdzie:\n",
    "- `accuracy` to wartość dokładności modelu (od 0 do 1).\n",
    "- Jeśli `accuracy < 0.2`, to P = 0.\n",
    "- Jeśli `accuracy >= 0.7`, to P = 1.\n",
    "\n",
    "<h2>Rozwiązanie</h2>\n",
    "\n",
    "- W tym zadaniu musisz musisz dołączyć plik Zadanie.ipynb, który po włączeniu utworzy plik odpowiedzi.csv gdzie będą znajdowały sie odpowiedzi, w formacie takim jak przykodp.csv, oraz plik odpowiedzi.csv.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Jeśli korzystasz z Google Colaba, odkomentuj poniższą linijkę\n",
    "# !pip install sacremoses\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'allegro/herbert-base-cased' \n",
    "tokenizer = AutoTokenizer.from_pretrained(\"allegro/herbert-base-cased\")\n",
    "model = AutoModel.from_pretrained(\"allegro/herbert-base-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed: int):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "\n",
    "# Setting a seed for reproducibility\n",
    "set_seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwitterDataset(Dataset):\n",
    "    def __init__(self, messages, labels, tokenizer, max_len):\n",
    "        self.messages = messages\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.messages)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        message = str(self.messages[index])\n",
    "        label = self.labels[index]\n",
    "\n",
    "        # Tokenize the input\n",
    "        encoding = self.tokenizer(\n",
    "            message,\n",
    "            max_length=self.max_len,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].squeeze(0),\n",
    "            'attention_mask': encoding['attention_mask'].squeeze(0),\n",
    "            'label': torch.tensor(label, dtype=torch.long)\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model klasyfikacji na bazie Herberta\n",
    "class TweetClassifier(nn.Module):\n",
    "    def __init__(self, base_model_name, num_classes):\n",
    "        \"\"\"\n",
    "        TODO: Zaimplementuj model z Herberta i warstwą klasyfikacji.\n",
    "        - base_model_name: nazwa modelu (np. allegro/herbert-base-cased).\n",
    "        - num_classes: liczba klas (5 w tym przypadku).\n",
    "        \"\"\"\n",
    "        super(TweetClassifier, self).__init__()\n",
    "        # TODO: Załaduj model Herberta i dodaj warstwę klasyfikacyjną.\n",
    "        pass\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        \"\"\"\n",
    "        TODO: Zaimplementuj forward pass modelu.\n",
    "        - Przyjmij input_ids i attention_mask.\n",
    "        - Zwróć wyniki klasyfikacji.\n",
    "        \"\"\"\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funkcja do trenowania modelu\n",
    "def train_model(model, data_loader, loss_fn, optimizer, device):\n",
    "    \"\"\"\n",
    "    TODO: Zaimplementuj pętlę treningową.\n",
    "    - model: model, który trenujesz.\n",
    "    - data_loader: DataLoader z danymi treningowymi.\n",
    "    - loss_fn: funkcja straty (np. CrossEntropyLoss).\n",
    "    - optimizer: optymalizator (np. AdamW).\n",
    "    - device: urządzenie (CPU/GPU).\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    for data in data_loader:\n",
    "        # TODO: Pobierz input_ids, attention_mask, labels z batcha.\n",
    "        # TODO: Oblicz predykcje modelu.\n",
    "        # TODO: Oblicz stratę.\n",
    "        # TODO: Wykonaj backpropagation i optymalizację.\n",
    "        pass\n",
    "\n",
    "def save_predictions(model, data_loader, device, output_file=\"odpowiedzi.csv\"):\n",
    "    \"\"\"\n",
    "    Generuje predykcje na danych testowych i zapisuje je do pliku CSV.\n",
    "    \n",
    "    Args:\n",
    "        test_loader (DataLoader): Dane testowe bez etykiet.\n",
    "        model (nn.Module): Wytrenowany model.\n",
    "        device (str): Urządzenie ('cuda' lub 'cpu').\n",
    "        output_file (str): Nazwa pliku wyjściowego (domyślnie 'odpowiedzi.csv').\n",
    "    \n",
    "    TODO:\n",
    "    1. Wykonaj predykcje dla wszystkich danych w test_loader.\n",
    "    2. Treści tweetów oraz przewidywane etykiety w formacie CSV.\n",
    "       - Format CSV: \n",
    "         | Content | Label |\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "    with torch.no_grad():\n",
    "        for data in data_loader:\n",
    "            # TODO: Pobierz input_ids, attention_mask, labels z batcha.\n",
    "            # TODO: Oblicz predykcje modelu.\n",
    "            # TODO: Policz poprawne predykcje.\n",
    "            pass\n",
    "    pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(file_path, tokenizer, max_len):\n",
    "    \"\"\"\n",
    "    TODO: Przygotuj dane do treningu i walidacji.\n",
    "    - file_path: ścieżka do pliku CSV.\n",
    "    - tokenizer: tokenizer Herberta.\n",
    "    - max_len: maksymalna długość tokenów.\n",
    "    \"\"\"\n",
    "    # TODO: Wczytaj dane z pliku.\n",
    "    # TODO: Przekonwertuj etykiety na numeryczne wartości.\n",
    "    # TODO: Zwróć dataset i DataLoader.\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"\n",
    "    TODO: Połącz wszystkie komponenty w celu wytrenowania modelu.\n",
    "    - Przygotuj dane treningowe i walidacyjne.\n",
    "    - Stwórz model.\n",
    "    - Wytrenuj model.\n",
    "    - Oceń model.\n",
    "    - Zapisz predykcje na zbiorze testowym.\n",
    "    \"\"\"\n",
    "    # Ustawienia\n",
    "    MODEL_NAME = 'allegro/herbert-base-cased'\n",
    "    MAX_LEN = 128\n",
    "    BATCH_SIZE = 16\n",
    "    NUM_EPOCHS = 5\n",
    "    NUM_CLASSES = 5\n",
    "    LEARNING_RATE = 2e-5\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    # TODO: Przygotuj tokenizer.\n",
    "    # TODO: Wczytaj dane i przygotuj DataLoadery.\n",
    "    # TODO: Stwórz model i przesuń na GPU.\n",
    "    # TODO: Zdefiniuj funkcję straty i optymalizator.\n",
    "    # TODO: Trenuj model i zapisuj metryki.\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fecam",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
