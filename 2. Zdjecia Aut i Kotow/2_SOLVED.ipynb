{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<h1>Zdjęcia Aut i Kotów</h1>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Wstęp</h1>\n",
    "Pamiętasz Marka Adamczyka, który prosił cię o pomoc w algorytmie znajdującym twórcę tweeta? Okazało się że ten pomysł to był strzał w dziesiątkę! Niestety przed wyjechaniem w podróż dookoła świata zapomniał ci on dać twoich należności za wykonaną pracę. Gdy po wielu miesiącach udało ci się z nim skontaktować, wspomniał ci on, że wczoraj zauważył, że zdjęcia samochodów, kotów, oraz innych fascynujących rzeczy, które zrobił są na tyle niewyraźne, że algorytm w jego telefonie nie jest w stanie ich automatycznie przypisać, i że przez będzie zmuszony do potwórzenia tej podróży. Niestety nie jest on ich w stanie sam przyporządkować ponieważ podczas tej podróży udało mu się zrobić tych zdjęć około... 60000. Nie masz pojęcia, jakim sposobem był on w stanie zrobić tyle zdjęć, lecz wiesz, że jeśli wybierze się w kolejną podróż, to raczej już nie zobaczysz swoich pieniędzy. Postanowiłeś więc zaproponować mu, iż napiszesz program, który automatycznie przyporządkuje zdjęcia do klas, których automat w jego telefonie nie był w stanie rozwiązać. Wywiąż się z obietnicy, jeśli wynik będzie zadowalający, to być może zobaczysz twoje należne pieniądze\n",
    "\n",
    "# <h2>Dostarczone pliki</h2>\n",
    "\n",
    "- `train_labeled.csv` - Dane treningowe z etykietami\n",
    "- `train_unlabeled.csv` - Dane treningowe bez etykiet\n",
    "- `test.csv` - Dane testowe\n",
    "- `przykodp.csv` - Przykładowy plik w formacie w jakim ma być `odpowiedzi.csv`.\n",
    "- `Zadanie.ipynb` - Notebook startowy do pracy nad modelem.\n",
    "\n",
    "# <h2>Foldery z obrazami</h2>\n",
    "\n",
    "  -  `/train_labeled` - Zawiera obrazy odpowiadające etykietom z train_labeled.csv.\n",
    "  -  `/train_unlabeled` - Zawiera obrazy odpowiadające danym z train_unlabeled.csv (bez etykiet).\n",
    "  -  `/test` - Zawiera obrazy do testowania.\n",
    "# <h2>Twoje zadanie</h2>\n",
    "\n",
    "### **1. Self-supervised Pretraining**\n",
    "- Zbuduj własną architekturę modelu.\n",
    "- Naucz model reprezentacji na danych `train_unlabeled.csv` za pomocą self-supervised learning. Możesz użyć metod takich jak:\n",
    "  - Contrastive learning (np. SimCLR).\n",
    "  - Autoenkodery.\n",
    "\n",
    "### **2. Fine-tuning**\n",
    "- Użyj wytrenowanego modelu do klasyfikacji na danych z częściowymi etykietami (`train_labeled.csv`).\n",
    "- Dostosuj hiperparametry (np. liczba epok, batch size, learning rate) dla swojego modelu.\n",
    "\n",
    "### **3. Ewaluacja**\n",
    "- Przeprowadź ewaluację swojego modelu na zbiorze testowym (`test.csv`).\n",
    "\n",
    "# <h2>Ograniczenia</h2>\n",
    "\n",
    "- Czas działania twojego kodu(trening i ewaluacja) na T4 na Google Colab powinien wynosić maksymalnie 10 minut.\n",
    "- Nie wolno korzystać z uprzednio wytrenowanych modeli oraz ze zbiorów danych innych niż dostarczony.\n",
    "- Twój kod może trenować się tylko i wyłącznie na danych z pliku train.csv.\n",
    "- Wszystkie dopuszczalne biblioteki są dostępne w pliku requirements.txt\n",
    "\n",
    "# <h2>Ocenanie</h2>\n",
    "\n",
    "Ocena zależy od wartości accuracy w sposób liniowy, przy czym:\n",
    "\n",
    "- Jeśli `accuracy < 0.5`, to liczba punktów wynosi 0.\n",
    "- Jeśli `accuracy >= 0.7`, to liczba punktów wynosi 1.\n",
    "- Dla wartości `accuracy` pomiędzy 0.5 a 0.7, liczba punktów rośnie liniowo.\n",
    "\n",
    "Wzór na obliczenie punktów (P):\n",
    "\n",
    "$$ P = \\frac{accuracy - 0.5}{0.2} $$\n",
    "\n",
    "# <h2>Ograniczenia</h2>\n",
    "\n",
    "1. Kod może korzystać wyłącznie z danych dostarczonych w plikach `train_labeled.csv`, `train_unlabeled.csv` oraz `test.csv`.\n",
    "2. Czas treningu i ewaluacji na GPU T4 w Google Colab powinien wynosić maksymalnie 10 minut.\n",
    "3. Użytkownik musi samodzielnie zbudować model od podstaw, bez korzystania z gotowych modeli (np. ResNet, VGG).\n",
    "\n",
    "<h2>Rozwiązanie</h2>\n",
    "\n",
    "- W tym zadaniu musisz musisz dołączyć plik Zadanie.ipynb, który po włączeniu utworzy plik odpowiedzi.csv gdzie będą znajdowały sie odpowiedzi, w formacie takim jak przykodp.csv, oraz plik odpowiedzi.csv.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from torchvision import transforms\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import os\n",
    "import csv\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "print(f\"using: {device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, csv_path, transform=None, labeled=True, test=False):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_path (str): Path to the CSV file.\n",
    "            transform (callable, optional): A function/transform to apply to the images.\n",
    "            labeled (bool): Whether the dataset includes labels.\n",
    "        \"\"\"\n",
    "        self.data = pd.read_csv(csv_path)\n",
    "        self.transform = transform\n",
    "        self.labeled = labeled\n",
    "        self.test = test\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.data.iloc[idx, 0]\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        if self.labeled:\n",
    "            if self.test:\n",
    "                return image, img_path\n",
    "            \n",
    "            label = self.data.iloc[idx, 1]\n",
    "            return image, label\n",
    "        else:\n",
    "            return image\n",
    "    \n",
    "def load_datasets(val_size=0):\n",
    "    \"\"\"\n",
    "    Funkcja ładująca dane z plików CSV i przygotowująca DataLoadery.\n",
    "    \n",
    "    TODO:\n",
    "    1. Wczytaj ścieżki do plików CSV dla zbiorów danych (np. train_labeled.csv, train_unlabeled.csv, test.csv).\n",
    "    2. Zdefiniuj odpowiednie transformacje dla obrazów (np. augmentacja, normalizacja).\n",
    "    3. Utwórz obiekty ImageDataset dla każdego z wymienionych zbiorów danych:\n",
    "       - Zbiór treningowy oznaczony (labeled).\n",
    "       - Zbiór treningowy nieoznaczony (unlabeled).\n",
    "       - Zbiór testowy.\n",
    "    4. Zainicjalizuj DataLoadery dla każdego zbioru, ustawiając odpowiednie parametry, takie jak:\n",
    "       - `batch_size`\n",
    "       - `shuffle` (dla zbioru treningowego).\n",
    "       - `num_workers` (dla optymalizacji wydajności).\n",
    "    5. Upewnij się, że DataLoadery zwracają dane w odpowiednim formacie (np. (image, label) dla labeled, tylko image dla unlabeled).\n",
    "    6. Przetestuj poprawność działania DataLoaderów na przykładzie małego batcha danych.\n",
    "    \n",
    "    Zwróć:\n",
    "    - `train_labeled_loader`: DataLoader dla oznaczonego zbioru treningowego.\n",
    "    - `train_unlabeled_loader`: DataLoader dla nieoznaczonego zbioru treningowego.\n",
    "    - `test_loader`: DataLoader dla zbioru testowego.\n",
    "    \"\"\"\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "    \n",
    "    train_labeled = ImageDataset(\"./train_labeled.csv\", transform=transform, labeled=True)\n",
    "    train_unlabeled = ImageDataset(\"./train_unlabeled.csv\", transform=transform, labeled=False)\n",
    "    test = ImageDataset(\"./test.csv\", transform=transform, labeled=True, test=True)\n",
    "    \n",
    "    train_size = int((1-val_size) * len(train_labeled))  # 80% for training\n",
    "    val_size = len(train_labeled) - train_size  # Remaining 20% for validation\n",
    "    \n",
    "    if val_size > 0:\n",
    "        train_dataset, val_dataset = random_split(train_labeled, [train_size, val_size])\n",
    "    \n",
    "        train_labeled_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "        val_labeled_loader = DataLoader(val_dataset, batch_size=32, shuffle=True)\n",
    "    else:\n",
    "        train_labeled_loader = DataLoader(train_labeled, batch_size=32, shuffle=True)\n",
    "        val_labeled_loader = None\n",
    "        \n",
    "    train_unlabeled_loader = DataLoader(train_unlabeled, batch_size=64, shuffle=True)\n",
    "    test_loader = DataLoader(test, batch_size=32)\n",
    "    \n",
    "    return train_labeled_loader, val_labeled_loader, train_unlabeled_loader, test_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SuperDuperProDINO(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SuperDuperProDINO, self).__init__()\n",
    "        self.stage = \"pretraining\"\n",
    "        \n",
    "        self.encoder = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(3, 16, (3,3)),\n",
    "            torch.nn.Dropout(0.3),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.AvgPool2d((2,2)),\n",
    "            torch.nn.Conv2d(16, 24, (3,3)),\n",
    "            torch.nn.Dropout(0.3),\n",
    "            torch.nn.Flatten(),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(4056, 50)\n",
    "        )\n",
    "        \n",
    "        self.decoder = torch.nn.Sequential(\n",
    "            torch.nn.Linear(50, 4056),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Unflatten(1, (24, 13, 13)),  # Matches output of encoder's Flatten input\n",
    "            torch.nn.Dropout(0.3),\n",
    "            torch.nn.ConvTranspose2d(24, 16, kernel_size=3, stride=1, padding=1),  # Output: (16, 13, 13)\n",
    "            torch.nn.Upsample(scale_factor=2, mode='nearest'),  # Upsamples to (16, 26, 26)\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Dropout(0.3),\n",
    "            torch.nn.ConvTranspose2d(16, 8, kernel_size=3, stride=1, padding=1),  # Output: (8, 26, 26)\n",
    "            torch.nn.Upsample(size=(32, 32), mode='nearest'),  # Upsamples directly to (8, 32, 32)\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.ConvTranspose2d(8, 3, kernel_size=3, stride=1, padding=1),  # Output: (3, 32, 32)\n",
    "            torch.nn.Sigmoid()  # Output activation for pixel values [0, 1]\n",
    "        )\n",
    "        \n",
    "        self.classification_head = torch.nn.Sequential(\n",
    "            torch.nn.Linear(50,10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.stage == \"pretraining\":\n",
    "            x = self.encoder(x)\n",
    "            x = self.decoder(x)\n",
    "            \n",
    "            return x\n",
    "        \n",
    "        elif self.stage == \"finetuning\" or self.stage == \"testing\":\n",
    "            x = self.encoder(x)\n",
    "            x = self.classification_head(x)\n",
    "            \n",
    "            return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def self_supervised_pretraining(unlabeled_loader, model, epochs=100, lr=0.01):\n",
    "    \"\"\"\n",
    "    Pretraining modelu w trybie self-supervised.\n",
    "\n",
    "    Args:\n",
    "        unlabeled_loader (DataLoader): Dane bez etykiet.\n",
    "        model (nn.Module): Model do pretrenowania.\n",
    "        epochs (int): Liczba epok pretrenowania.\n",
    "        lr (float): Współczynnik uczenia.\n",
    "\n",
    "    TODO:\n",
    "    1. Zaimplementuj metodę self-supervised:\n",
    "       - Możesz użyć autoenkodera, kontrastowego uczenia (SimCLR, BYOL), itp.\n",
    "    2. Ustaw odpowiednią funkcję straty i optymalizator.\n",
    "    3. Przeprowadź trening i monitoruj utratę (loss).\n",
    "    \"\"\"\n",
    "    criterion = torch.nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    model.stage = \"pretraining\"\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        running_loss = []\n",
    "        for imgs in unlabeled_loader:\n",
    "            imgs = imgs.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            otpt = model(imgs)\n",
    "            \n",
    "            loss = criterion(otpt, imgs)\n",
    "            loss.backward()\n",
    "            \n",
    "            running_loss.append(loss.item())\n",
    "            \n",
    "            optimizer.step()\n",
    "        print(f\"Epoch {epoch+1}|{epochs}: Train Loss: {sum(running_loss)/len(running_loss)}\")\n",
    "        running_loss = []\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fine_tune_model(labeled_loader, model, epochs, lr):\n",
    "    \"\"\"\n",
    "    Fine-tuning modelu na danych z etykietami.\n",
    "\n",
    "    Args:\n",
    "        labeled_loader (DataLoader): Dane z etykietami.\n",
    "        model (nn.Module): Model do trenowania.\n",
    "        epochs (int): Liczba epok treningu.\n",
    "        lr (float): Współczynnik uczenia.\n",
    "\n",
    "    TODO:\n",
    "    1. Dodaj warstwę klasyfikacyjną do modelu.\n",
    "    2. Ustaw funkcję straty (np. CrossEntropyLoss) i optymalizator.\n",
    "    3. Wytrenuj model na zbiorze labeled.\n",
    "    \"\"\"\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    model.stage = \"finetuning\"\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        running_loss = []\n",
    "        for imgs, labels in labeled_loader:\n",
    "            imgs = imgs.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            otpt = model(imgs)\n",
    "            \n",
    "            loss = criterion(otpt, labels.to(device))\n",
    "            loss.backward()\n",
    "            \n",
    "            running_loss.append(loss.item())\n",
    "            \n",
    "            optimizer.step()\n",
    "        print(f\"Epoch {epoch+1}|{epochs}: Train Loss: {sum(running_loss)/len(running_loss)}\")\n",
    "        running_loss = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(test_loader, model):\n",
    "    model.stage = \"testing\"\n",
    "    with torch.no_grad():\n",
    "        score = 0\n",
    "        max_score = 0\n",
    "        for imgs, labels in test_loader:\n",
    "            imgs = imgs.to(device)\n",
    "            \n",
    "            otpt = model(imgs)\n",
    "            \n",
    "            preds = torch.argmax(otpt, dim=1)\n",
    "            \n",
    "            score += torch.sum(preds==labels.to(device))\n",
    "            max_score += labels.shape[0]\n",
    "            \n",
    "    print(f\"Wynik to: {score}/{max_score} ({score/max_score})\")\n",
    "                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def save_predictions(test_loader, model, output_file=\"odpowiedzi.csv\"):\n",
    "    \"\"\"\n",
    "    Generuje predykcje na danych testowych i zapisuje je do pliku CSV.\n",
    "    \n",
    "    Args:\n",
    "        test_loader (DataLoader): Dane testowe bez etykiet.\n",
    "        model (nn.Module): Wytrenowany model.\n",
    "        output_file (str): Nazwa pliku wyjściowego (domyślnie 'predictions.csv').\n",
    "    \n",
    "    TODO:\n",
    "    1. Wykonaj predykcje dla wszystkich obrazów w test_loader.\n",
    "    2. Zapisz ścieżki do obrazów oraz przewidywane etykiety w formacie CSV.\n",
    "       - Format CSV: \n",
    "         | image_path | label |\n",
    "    \"\"\"\n",
    "    \n",
    "    model.eval()\n",
    "    model.stage = \"testing\"\n",
    "    \n",
    "    predictions = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for imgs, imgs_paths in test_loader:\n",
    "            imgs = imgs.to(device)\n",
    "            \n",
    "            otpt = model(imgs)\n",
    "            \n",
    "            preds = torch.argmax(otpt, dim=1).cpu().tolist()\n",
    "\n",
    "            for path, label in zip(imgs_paths, preds):\n",
    "                predictions.append((path, label))\n",
    "    \n",
    "    # Zapis wyników do pliku CSV\n",
    "    with open(output_file, mode=\"w\", newline=\"\") as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([\"image_path\", \"label\"])  # Nagłówek pliku CSV\n",
    "        writer.writerows(predictions)\n",
    "            \n",
    "            \n",
    "            \n",
    "    print(f\"Zapisano predykcje do pliku csv!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rozpoczęcie pretreningu...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[78], line 20\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;66;03m# print(\"Generowanie predykcji na danych testowych...\")\u001b[39;00m\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;66;03m# save_predictions(test_loader, model, output_file=\"odpowiedzi.csv\")\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 20\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[78], line 7\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m model \u001b[38;5;241m=\u001b[39m SuperDuperProDINO()\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRozpoczęcie pretreningu...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 7\u001b[0m \u001b[43mself_supervised_pretraining\u001b[49m\u001b[43m(\u001b[49m\u001b[43munlabeled_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munlabeled_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.001\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRozpoczęcie fine-tuningu...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     10\u001b[0m fine_tune_model(labeled_loader\u001b[38;5;241m=\u001b[39mlabeled_loader, model\u001b[38;5;241m=\u001b[39mmodel, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m, lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m)\n",
      "Cell \u001b[1;32mIn[72], line 31\u001b[0m, in \u001b[0;36mself_supervised_pretraining\u001b[1;34m(unlabeled_loader, model, epochs, lr)\u001b[0m\n\u001b[0;32m     28\u001b[0m otpt \u001b[38;5;241m=\u001b[39m model(imgs)\n\u001b[0;32m     30\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(otpt, imgs)\n\u001b[1;32m---> 31\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     33\u001b[0m running_loss\u001b[38;5;241m.\u001b[39mappend(loss\u001b[38;5;241m.\u001b[39mitem())\n\u001b[0;32m     35\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[1;32mc:\\Users\\lewy7\\Documents\\GitHub\\MIKO Contest\\venv\\Lib\\site-packages\\torch\\_tensor.py:581\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    572\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    573\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    574\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    579\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    580\u001b[0m     )\n\u001b[1;32m--> 581\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    582\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    583\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\lewy7\\Documents\\GitHub\\MIKO Contest\\venv\\Lib\\site-packages\\torch\\autograd\\__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\lewy7\\Documents\\GitHub\\MIKO Contest\\venv\\Lib\\site-packages\\torch\\autograd\\graph.py:825\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    823\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    824\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 825\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    827\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    828\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    829\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    labeled_loader, _, unlabeled_loader, test_loader = load_datasets()\n",
    "\n",
    "    model = SuperDuperProDINO().to(device)\n",
    "\n",
    "    print(\"Rozpoczęcie pretreningu...\")\n",
    "    self_supervised_pretraining(unlabeled_loader=unlabeled_loader, model=model, epochs=3, lr=0.001)\n",
    "\n",
    "    print(\"Rozpoczęcie fine-tuningu...\")\n",
    "    fine_tune_model(labeled_loader=labeled_loader, model=model, epochs=50, lr=0.001)\n",
    "\n",
    "    print(\"Rozpoczęto predykcję klas ze zbioru testowego...\")\n",
    "    save_predictions(test_loader=test_loader, model=model)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rozpoczęcie pretreningu...\n",
      "Epoch 1|5: Train Loss: 0.02215034877668319\n",
      "Epoch 2|5: Train Loss: 0.013482788211664794\n",
      "Epoch 3|5: Train Loss: 0.01221939077422845\n",
      "Epoch 4|5: Train Loss: 0.011748988325500793\n",
      "Epoch 5|5: Train Loss: 0.01153499772834866\n",
      "Rozpoczęcie fine-tuningu...\n",
      "Epoch 1|30: Train Loss: 2.1086151969264932\n",
      "Epoch 2|30: Train Loss: 1.841505658458656\n",
      "Epoch 3|30: Train Loss: 1.674167319082878\n",
      "Epoch 4|30: Train Loss: 1.5346079493912173\n",
      "Epoch 5|30: Train Loss: 1.3970847297722184\n",
      "Epoch 6|30: Train Loss: 1.331325972583932\n",
      "Epoch 7|30: Train Loss: 1.2507357639326175\n",
      "Epoch 8|30: Train Loss: 1.1613928348245754\n",
      "Epoch 9|30: Train Loss: 1.1221788189780544\n",
      "Epoch 10|30: Train Loss: 1.0713389792912442\n",
      "Epoch 11|30: Train Loss: 1.0327525911196855\n",
      "Epoch 12|30: Train Loss: 0.9841045351095603\n",
      "Epoch 13|30: Train Loss: 0.9389350011315144\n",
      "Epoch 14|30: Train Loss: 0.8925288025761994\n",
      "Epoch 15|30: Train Loss: 0.8441313929121259\n",
      "Epoch 16|30: Train Loss: 0.7969137803769447\n",
      "Epoch 17|30: Train Loss: 0.8072827605294509\n",
      "Epoch 18|30: Train Loss: 0.7497359682136858\n",
      "Epoch 19|30: Train Loss: 0.6921132462964931\n",
      "Epoch 20|30: Train Loss: 0.6646090724938353\n",
      "Epoch 21|30: Train Loss: 0.6445516444427867\n",
      "Epoch 22|30: Train Loss: 0.6279360689747502\n",
      "Epoch 23|30: Train Loss: 0.5859889312529228\n",
      "Epoch 24|30: Train Loss: 0.5747886556135097\n",
      "Epoch 25|30: Train Loss: 0.5721077730118389\n",
      "Epoch 26|30: Train Loss: 0.5492612488672767\n",
      "Epoch 27|30: Train Loss: 0.5296211704401903\n",
      "Epoch 28|30: Train Loss: 0.5083167204554652\n",
      "Epoch 29|30: Train Loss: 0.5019830780130037\n",
      "Epoch 30|30: Train Loss: 0.4658438267422394\n",
      "Rozpoczęto predykcję klas ze zbioru testowego...\n",
      "Wynik to: 91/250 (0.36400002241134644)\n"
     ]
    }
   ],
   "source": [
    "labeled_loader, val_loader, unlabeled_loader, test_loader = load_datasets(0.1)\n",
    "\n",
    "model = SuperDuperProDINO().to(device)\n",
    "\n",
    "print(\"Rozpoczęcie pretreningu...\")\n",
    "self_supervised_pretraining(unlabeled_loader=unlabeled_loader, model=model, epochs=5, lr=0.001)\n",
    "\n",
    "print(\"Rozpoczęcie fine-tuningu...\")\n",
    "fine_tune_model(labeled_loader=labeled_loader, model=model, epochs=30, lr=0.001)\n",
    "\n",
    "print(\"Rozpoczęto predykcję klas ze zbioru testowego...\")\n",
    "test_model(test_loader=val_loader, model=model)\n",
    "\n",
    "# print(\"Generowanie predykcji na danych testowych...\")\n",
    "# save_predictions(test_loader, model, output_file=\"odpowiedzi.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rozpoczęto predykcję klas ze zbioru testowego...\n",
      "Wynik to: 1959/2250 (0.8706666827201843)\n"
     ]
    }
   ],
   "source": [
    "print(\"Rozpoczęto predykcję klas ze zbioru testowego...\")\n",
    "test_model(test_loader=labeled_loader, model=model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
